{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1182853,"sourceType":"datasetVersion","datasetId":672162}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🏥 Mini Capstone Project – Medical Data Processing  \n## 📌 Overview  \nWelcome to the **Mini Capstone Project!** This project challenges you to apply **Python, Object-Oriented Programming (OOP), NumPy, and Data Structures** to solve a real-world medical problem.  \n\n### 🎯 Objectives  \n- Implement **OOP concepts** for structured code.  \n- Utilize **NumPy** for efficient medical data processing.  \n- Manage patient data using **data structures** like lists and dictionaries.  \n- Work collaboratively in **Kaggle’s shared workspace**.  ","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:57:24.111957Z","iopub.execute_input":"2025-03-20T16:57:24.112300Z","iopub.status.idle":"2025-03-20T16:57:24.120872Z","shell.execute_reply.started":"2025-03-20T16:57:24.112274Z","shell.execute_reply":"2025-03-20T16:57:24.119907Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/disease-symptom-description-dataset/symptom_Description.csv\n/kaggle/input/disease-symptom-description-dataset/Symptom-severity.csv\n/kaggle/input/disease-symptom-description-dataset/symptom_precaution.csv\n/kaggle/input/disease-symptom-description-dataset/dataset.csv\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"import pandas as pd\nimport os\nfrom collections import deque\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:57:24.124153Z","iopub.execute_input":"2025-03-20T16:57:24.124562Z","iopub.status.idle":"2025-03-20T16:57:24.134273Z","shell.execute_reply.started":"2025-03-20T16:57:24.124520Z","shell.execute_reply":"2025-03-20T16:57:24.133147Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/disease-symptom-description-dataset'\nFILE_NAME = 'dataset.csv'\nDATA_PATH = os.path.join(INPUT_DIR, FILE_NAME)\n\n# Verify available files\nprint(\"Available files in dataset:\")\nfor dirname, _, filenames in os.walk(INPUT_DIR):\n    for filename in filenames:\n        print(f\" - {filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:57:24.136079Z","iopub.execute_input":"2025-03-20T16:57:24.136462Z","iopub.status.idle":"2025-03-20T16:57:24.155226Z","shell.execute_reply.started":"2025-03-20T16:57:24.136424Z","shell.execute_reply":"2025-03-20T16:57:24.154091Z"}},"outputs":[{"name":"stdout","text":"Available files in dataset:\n - symptom_Description.csv\n - Symptom-severity.csv\n - symptom_precaution.csv\n - dataset.csv\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"class SymptomChecker:\n    def __init__(self):\n        self.medical_data = self._load_data()\n        self.conditions = self._prepare_data()\n    \n    def _load_data(self):\n        \"\"\"Load and validate the clinical dataset\"\"\"\n        try:\n            print(f\"\\nLoading primary dataset: {FILE_NAME}\")\n            df = pd.read_csv(DATA_PATH)\n            return df\n        except FileNotFoundError:\n            print(\"\\nERROR: Missing dataset file. Verify:\")\n            print(f\"1. File exists in {INPUT_DIR}\")\n            print(f\"2. Correct file name (you have: {FILE_NAME})\")\n            exit()\n\n    def _prepare_data(self):\n        \"\"\"Process disease-symptom relationships\"\"\"\n        condition_db = {}\n        for _, row in self.medical_data.iterrows():\n            symptoms = [s.strip().lower() for s in row[1:].dropna().tolist()]  # Fetch all symptoms dynamically\n            condition_db[row['Disease'].strip()] = {'symptoms': np.array(symptoms, dtype=object)}  # Store as NumPy array\n        return condition_db\n\n    def analyze(self, symptoms):\n        \"\"\"Improved symptom analysis logic using NumPy\"\"\"\n        matches = []\n        clean_symptoms = np.array([s.strip().lower() for s in symptoms], dtype=object)\n        \n        for condition, data in self.conditions.items():\n            common = np.intersect1d(clean_symptoms, data['symptoms'])  # NumPy-based intersection\n            if common.size > 0:\n                matches.append((condition, common.size))\n        \n        return sorted(matches, key=lambda x: x[1], reverse=True)[:5]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:57:24.159512Z","iopub.execute_input":"2025-03-20T16:57:24.159896Z","iopub.status.idle":"2025-03-20T16:57:24.176066Z","shell.execute_reply.started":"2025-03-20T16:57:24.159857Z","shell.execute_reply":"2025-03-20T16:57:24.175065Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def main():\n    print(\"\\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n    print(\"  Medical Symptom Analysis System\")\n    print(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\")\n    \n    name = input(\"\\nPatient Name: \").strip()\n    symptoms = input(\"Symptoms (comma-separated): \").split(',')\n    \n    engine = SymptomChecker()\n    results = engine.analyze(symptoms)\n    \n    print(f\"\\nAssessment for {name}:\")\n    if not results:\n        print(\"⚠️ No clear matches - consult a physician\")\n        return\n    \n    for idx, (condition, score) in enumerate(results, 1):\n        print(f\"{idx}. {condition} ({score} symptom matches)\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T16:57:24.177329Z","iopub.execute_input":"2025-03-20T16:57:24.177680Z","iopub.status.idle":"2025-03-20T16:57:38.418830Z","shell.execute_reply.started":"2025-03-20T16:57:24.177650Z","shell.execute_reply":"2025-03-20T16:57:38.417771Z"}},"outputs":[{"name":"stdout","text":"\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n  Medical Symptom Analysis System\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nPatient Name:  emm\nSymptoms (comma-separated):  vomiting, fever, headache\n"},{"name":"stdout","text":"\nLoading primary dataset: dataset.csv\n\nAssessment for emm:\n1. Paralysis (brain hemorrhage) (2 symptom matches)\n2. Malaria (2 symptom matches)\n3. Dengue (2 symptom matches)\n4. Typhoid (2 symptom matches)\n5. Hypoglycemia (2 symptom matches)\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}